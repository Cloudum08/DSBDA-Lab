{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjdMX/qN0R5Ra2i62vUYn2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cloudum08/DSBDA-Lab/blob/main/DSBDAL_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Extract Sample document and apply following document preprocessing methods:\n",
        "Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.\n",
        "2. Create representation of document by calculating Term Frequency and Inverse Document\n",
        "Frequency."
      ],
      "metadata": {
        "id": "lLvoCS6um-8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization, POS Tagging, stop words removal, Stemming and\n",
        "Lemmatization:**"
      ],
      "metadata": {
        "id": "uoYR9vGNnApT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Download the required packages"
      ],
      "metadata": {
        "id": "I4ZV15vjnEOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aao__Q4pnOAj",
        "outputId": "7852ff35-49b9-4a6c-a3d5-1fbf1afe904c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Initialize the text"
      ],
      "metadata": {
        "id": "yKraTnkGnZQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text= \"Tokenization is the first step in text analytics. The process of breaking down a text paragraph into smaller chunks such as words or sentences is called Tokenization.\""
      ],
      "metadata": {
        "id": "MVSaS0y8nZ3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Perform Tokenization"
      ],
      "metadata": {
        "id": "rG7Of-Zendiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentence Tokenization\n",
        "from nltk.tokenize import sent_tokenize\n",
        "tokenized_text= sent_tokenize(text)\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ8Uv6MSnhzT",
        "outputId": "197e9b6f-1425-498a-fa64-bd20811a091b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tokenization is the first step in text analytics  The process of breaking down a text paragraph into smaller chunks such as words or sentences is called Tokenization']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Tokenization\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokenized_word=word_tokenize(text)\n",
        "print(tokenized_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmB4dF6in0sY",
        "outputId": "5c2f47b2-e307-4519-ed78-1812f839133a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tokenization', 'is', 'the', 'first', 'step', 'in', 'text', 'analytics', 'The', 'process', 'of', 'breaking', 'down', 'a', 'text', 'paragraph', 'into', 'smaller', 'chunks', 'such', 'as', 'words', 'or', 'sentences', 'is', 'called', 'Tokenization']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Removing Punctuations and Stop Word"
      ],
      "metadata": {
        "id": "r9PL--wTn4XT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print stop words of English\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "stop_words=set(stopwords.words(\"english\"))\n",
        "print(stop_words)\n",
        "#text= \"How to remove stop words with NLTK library in Python?\"\n",
        "text= re.sub('[^a-zA-Z]', ' ',text)\n",
        "tokens = word_tokenize(text.lower())\n",
        "filtered_text=[]\n",
        "for w in tokens:\n",
        "  if w not in stop_words:\n",
        "    filtered_text.append(w)\n",
        "print(\"Tokenized Sentence:\",tokens)\n",
        "print(\"Filterd Sentence:\",filtered_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW7eG3v5n61r",
        "outputId": "629b8806-7efe-4f66-aad2-818f40634e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'y', 'll', 's', 'its', 'further', 'i', 'your', 'why', 'ain', 'isn', \"weren't\", 'over', 'having', 'herself', 'shan', 'from', \"hasn't\", 'of', 'above', \"don't\", 'yourselves', 'was', \"you'd\", 'hasn', 'him', 'under', 'wasn', 'them', 'again', 'such', 't', 'themselves', \"mightn't\", 'will', \"mustn't\", 'off', 'to', 'were', 'down', 'doing', \"won't\", 'those', 'both', 'and', 'so', 'does', 'some', 'here', 'do', 'won', 'his', 'only', 'just', 'few', \"isn't\", 'a', 'when', 'by', 'mustn', 'has', 'am', \"it's\", 'into', \"that'll\", 'these', 'is', 'been', 'through', 'yours', 'yourself', 'which', 'on', 'this', 've', 'any', 'if', 'during', 'hadn', \"doesn't\", 'ours', 'ma', 'don', 'didn', 'd', 'as', 'she', 'himself', 'whom', 'no', 'me', 'we', 'their', 'below', 'once', 'most', 'other', 'out', 'or', 'did', \"shouldn't\", \"you're\", 'myself', 'nor', 'then', 'between', 'that', 'have', \"wouldn't\", 'it', 'couldn', 'how', 'her', 'an', \"didn't\", 'what', \"wasn't\", 'there', 'until', \"you'll\", 'are', 'each', 'but', 'o', 'all', 'in', 're', 'with', \"needn't\", 'very', 'about', 'after', 'too', 'm', 'shouldn', 'before', \"haven't\", 'the', \"aren't\", 'mightn', 'you', 'who', 'my', \"hadn't\", \"she's\", 'had', 'ourselves', 'at', 'they', 'itself', \"shan't\", 'be', 'wouldn', 'being', \"should've\", \"you've\", 'haven', 'up', 'theirs', 'hers', 'same', 'he', 'than', 'while', 'should', 'weren', 'because', 'where', 'aren', 'against', 'our', \"couldn't\", 'needn', 'own', 'doesn', 'more', 'for', 'can', 'now', 'not'}\n",
            "Tokenized Sentence: ['tokenization', 'is', 'the', 'first', 'step', 'in', 'text', 'analytics', 'the', 'process', 'of', 'breaking', 'down', 'a', 'text', 'paragraph', 'into', 'smaller', 'chunks', 'such', 'as', 'words', 'or', 'sentences', 'is', 'called', 'tokenization']\n",
            "Filterd Sentence: ['tokenization', 'first', 'step', 'text', 'analytics', 'process', 'breaking', 'text', 'paragraph', 'smaller', 'chunks', 'words', 'sentences', 'called', 'tokenization']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 : Perform Stemming"
      ],
      "metadata": {
        "id": "8iX-9uxWwNSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "e_words= [\"wait\", \"waiting\", \"waited\", \"waits\"]\n",
        "ps =PorterStemmer()\n",
        "for w in e_words:\n",
        "  rootWord=ps.stem(w)\n",
        "print(rootWord)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41uoq5vjwN74",
        "outputId": "7aafa3bd-9572-4361-926a-3015ea50c018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wait\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Perform Lemmatization"
      ],
      "metadata": {
        "id": "O1sQRAtSwY_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "text = \"studies studying cries cry\"\n",
        "tokenization = word_tokenize(text)\n",
        "for w in tokenization:\n",
        "  print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2uYB-ORwZy_",
        "outputId": "51e2a816-429f-4308-a96d-0a00658fdbb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemma for studies is study\n",
            "Lemma for studying is studying\n",
            "Lemma for cries is cry\n",
            "Lemma for cry is cry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Apply POS Tagging to text"
      ],
      "metadata": {
        "id": "LbFwDaVlwh1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "data=\"The pink sweater fit her perfectly\"\n",
        "words=word_tokenize(data)\n",
        "for word in words:\n",
        "    print(nltk.pos_tag([word]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2trIi1Ywibn",
        "outputId": "8a5797ab-b2b2-4b5c-d171-699803b7568d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT')]\n",
            "[('pink', 'NN')]\n",
            "[('sweater', 'NN')]\n",
            "[('fit', 'NN')]\n",
            "[('her', 'PRP$')]\n",
            "[('perfectly', 'RB')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algorithm for Create representation of document by calculating TFIDF**"
      ],
      "metadata": {
        "id": "1SXkz-87wsnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import the necessary libraries."
      ],
      "metadata": {
        "id": "k3cJhv__wzoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "HKWlfuVzwvk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Initialize the Documents."
      ],
      "metadata": {
        "id": "0m7wKNApw9d3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentA = 'Jupiter is the largest Planet'\n",
        "documentB = 'Mars is the fourth planet from the Sun'"
      ],
      "metadata": {
        "id": "eEsfTTibw9_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Create BagofWords (BoW) for Document A and B."
      ],
      "metadata": {
        "id": "X-CSYy05xA2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bagOfWordsA = documentA.split(' ')\n",
        "bagOfWordsA\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p_igV-HxC6q",
        "outputId": "edcddd47-45aa-4988-a1e4-0d932da08d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jupiter', 'is', 'the', 'largest', 'Planet']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bagOfWordsB = documentB.split(' ')\n",
        "bagOfWordsB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vczazd0ExC_f",
        "outputId": "693c5ab7-511c-488d-82f6-7ee54cf958b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mars', 'is', 'the', 'fourth', 'planet', 'from', 'the', 'Sun']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Create Collection of Unique words from Document A and B."
      ],
      "metadata": {
        "id": "S2YfKLYmxLlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB))\n",
        "uniqueWords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRffEv1SxYlf",
        "outputId": "66ca0478-032b-42a7-a555-9cc1f41c9ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Jupiter',\n",
              " 'Mars',\n",
              " 'Planet',\n",
              " 'Sun',\n",
              " 'fourth',\n",
              " 'from',\n",
              " 'is',\n",
              " 'largest',\n",
              " 'planet',\n",
              " 'the'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Create a dictionary of words and their occurrence for each document in the corpus"
      ],
      "metadata": {
        "id": "9PkECs3Bxk-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsA:\n",
        "  numOfWordsA[word] += 1\n",
        "  numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsB:\n",
        "  numOfWordsB[word] += 1"
      ],
      "metadata": {
        "id": "lweIM9wDxmYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numOfWordsA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U63DaRdxrUa",
        "outputId": "f53df997-8710-42b4-ee77-3ecd29a45daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'planet': 0,\n",
              " 'Jupiter': 1,\n",
              " 'is': 1,\n",
              " 'Mars': 0,\n",
              " 'Sun': 0,\n",
              " 'largest': 1,\n",
              " 'from': 0,\n",
              " 'Planet': 1,\n",
              " 'the': 1,\n",
              " 'fourth': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numOfWordsB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-7T6CwUxuuC",
        "outputId": "878f2bdd-90c2-4fff-c802-24cb345135c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'planet': 1,\n",
              " 'Jupiter': 0,\n",
              " 'is': 1,\n",
              " 'Mars': 1,\n",
              " 'Sun': 1,\n",
              " 'largest': 0,\n",
              " 'from': 1,\n",
              " 'Planet': 0,\n",
              " 'the': 2,\n",
              " 'fourth': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Compute the term frequency for each of our documents."
      ],
      "metadata": {
        "id": "NQPv6tbExyqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computeTF(wordDict, bagOfWords):\n",
        "  tfDict = {}\n",
        "  bagOfWordsCount = len(bagOfWords)\n",
        "  for word, count in wordDict.items():\n",
        "    tfDict[word] = count / float(bagOfWordsCount)\n",
        "  return tfDict\n",
        "tfA = computeTF(numOfWordsA, bagOfWordsA)\n",
        "tfB = computeTF(numOfWordsB, bagOfWordsB)"
      ],
      "metadata": {
        "id": "PR7XPmIgxzPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYVmG2fRx2SE",
        "outputId": "6bd357db-a8cb-4da6-b929-969ac66b1ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'planet': 0.0,\n",
              " 'Jupiter': 0.2,\n",
              " 'is': 0.2,\n",
              " 'Mars': 0.0,\n",
              " 'Sun': 0.0,\n",
              " 'largest': 0.2,\n",
              " 'from': 0.0,\n",
              " 'Planet': 0.2,\n",
              " 'the': 0.2,\n",
              " 'fourth': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ761Qqdx490",
        "outputId": "4ddc1dde-dcdf-4194-ce0e-022e800ba88a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'planet': 0.125,\n",
              " 'Jupiter': 0.0,\n",
              " 'is': 0.125,\n",
              " 'Mars': 0.125,\n",
              " 'Sun': 0.125,\n",
              " 'largest': 0.0,\n",
              " 'from': 0.125,\n",
              " 'Planet': 0.0,\n",
              " 'the': 0.25,\n",
              " 'fourth': 0.125}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Compute the term Inverse Document Frequency."
      ],
      "metadata": {
        "id": "Xn7J494Fx84E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computeIDF(documents):\n",
        "  import math\n",
        "  N = len(documents)\n",
        "  idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
        "  for document in documents:\n",
        "    for word, val in document.items():\n",
        "      if val > 0:\n",
        "        idfDict[word] += 1\n",
        "  for word, val in idfDict.items():\n",
        "    idfDict[word] = math.log(N / float(val))\n",
        "  return idfDict\n",
        "idfs = computeIDF([numOfWordsA, numOfWordsB])\n",
        "idfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j5NW3lux9Vs",
        "outputId": "6517d585-5e95-4ee5-e8fa-6f4d4081c348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'planet': 0.6931471805599453,\n",
              " 'Jupiter': 0.6931471805599453,\n",
              " 'is': 0.0,\n",
              " 'Mars': 0.6931471805599453,\n",
              " 'Sun': 0.6931471805599453,\n",
              " 'largest': 0.6931471805599453,\n",
              " 'from': 0.6931471805599453,\n",
              " 'Planet': 0.6931471805599453,\n",
              " 'the': 0.0,\n",
              " 'fourth': 0.6931471805599453}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Compute the term TF/IDF for all words."
      ],
      "metadata": {
        "id": "bpqDgwr8yFCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computeTFIDF(tfBagOfWords, idfs):\n",
        "  tfidf = {}\n",
        "  for word, val in tfBagOfWords.items():\n",
        "    tfidf[word] = val * idfs[word]\n",
        "  return tfidf\n",
        "\n",
        "tfidfA = computeTFIDF(tfA, idfs)\n",
        "tfidfB = computeTFIDF(tfB, idfs)\n",
        "df = pd.DataFrame([tfidfA, tfidfB])\n"
      ],
      "metadata": {
        "id": "SmL4et56yFnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "weHANCeMyJ3-",
        "outputId": "e8b623ca-091e-4d7c-cc86-6dd55aaa0a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     planet   Jupiter   is      Mars       Sun   largest      from    Planet  \\\n",
              "0  0.000000  0.138629  0.0  0.000000  0.000000  0.138629  0.000000  0.138629   \n",
              "1  0.086643  0.000000  0.0  0.086643  0.086643  0.000000  0.086643  0.000000   \n",
              "\n",
              "   the    fourth  \n",
              "0  0.0  0.000000  \n",
              "1  0.0  0.086643  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-339ec6e7-9882-4dfd-9aa0-3eeb62d00663\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>planet</th>\n",
              "      <th>Jupiter</th>\n",
              "      <th>is</th>\n",
              "      <th>Mars</th>\n",
              "      <th>Sun</th>\n",
              "      <th>largest</th>\n",
              "      <th>from</th>\n",
              "      <th>Planet</th>\n",
              "      <th>the</th>\n",
              "      <th>fourth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138629</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138629</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138629</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.086643</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.086643</td>\n",
              "      <td>0.086643</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086643</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.086643</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-339ec6e7-9882-4dfd-9aa0-3eeb62d00663')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-339ec6e7-9882-4dfd-9aa0-3eeb62d00663 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-339ec6e7-9882-4dfd-9aa0-3eeb62d00663');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7800a138-d4b6-47fa-b04a-4cc49e14d1b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7800a138-d4b6-47fa-b04a-4cc49e14d1b6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7800a138-d4b6-47fa-b04a-4cc49e14d1b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"planet\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061266133966784195,\n        \"min\": 0.0,\n        \"max\": 0.08664339756999316,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.08664339756999316,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Jupiter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09802581434685471,\n        \"min\": 0.0,\n        \"max\": 0.13862943611198905,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.13862943611198905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061266133966784195,\n        \"min\": 0.0,\n        \"max\": 0.08664339756999316,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.08664339756999316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sun\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061266133966784195,\n        \"min\": 0.0,\n        \"max\": 0.08664339756999316,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.08664339756999316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"largest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09802581434685471,\n        \"min\": 0.0,\n        \"max\": 0.13862943611198905,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"from\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061266133966784195,\n        \"min\": 0.0,\n        \"max\": 0.08664339756999316,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.08664339756999316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Planet\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09802581434685471,\n        \"min\": 0.0,\n        \"max\": 0.13862943611198905,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fourth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061266133966784195,\n        \"min\": 0.0,\n        \"max\": 0.08664339756999316,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.08664339756999316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9QLxQ0gyOw2",
        "outputId": "1870813b-66a3-4b1d-f6d8-a9cf60f89e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'planet': 0.0,\n",
              " 'Jupiter': 0.13862943611198905,\n",
              " 'is': 0.0,\n",
              " 'Mars': 0.0,\n",
              " 'Sun': 0.0,\n",
              " 'largest': 0.13862943611198905,\n",
              " 'from': 0.0,\n",
              " 'Planet': 0.13862943611198905,\n",
              " 'the': 0.0,\n",
              " 'fourth': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNKzuJCTyQN2",
        "outputId": "0b81dd8c-b739-4592-883d-8ae83371417d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'planet': 0.08664339756999316,\n",
              " 'Jupiter': 0.0,\n",
              " 'is': 0.0,\n",
              " 'Mars': 0.08664339756999316,\n",
              " 'Sun': 0.08664339756999316,\n",
              " 'largest': 0.0,\n",
              " 'from': 0.08664339756999316,\n",
              " 'Planet': 0.0,\n",
              " 'the': 0.0,\n",
              " 'fourth': 0.08664339756999316}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**In this way we have done text data analysis using TF IDF algorithm"
      ],
      "metadata": {
        "id": "RfWNOTZRyhSd"
      }
    }
  ]
}